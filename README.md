# üöÄ LLM Optimization & Specialized Training Hub

A centralized repository of high-performance fine-tuning recipes, reasoning models, and edge deployment optimizations developed for real-world production environments.

## üìÇ Project Categories

### Reasoning & RLHF
Implementing Group Relative Policy Optimization (GRPO) for logic and math reasoning without a separate Critic model.

* **[Reward functions](gpt_oss_20B_GRPO/README.md)**: Logic and math reasoning without a separate Critic model, popularized by DeepSeek-R1....
* **[Qwen3 8B FP8 GRPO](Qwen3_8B_FP8_GRPO/README.md)**: Logic and math reasoning without a separate Critic model, popularized by DeepSeek-R1....
* **[Reward functions](gpt_oss_20B_GRPO_BF16/README.md)**: Logic and math reasoning without a separate Critic model, popularized by DeepSeek-R1....
* **[Qwen3 (14B)-Reasoning-Conversational](Qwen3_14B_Reasoning_Conversational/README.md)**: High-performance LLM optimization implemented with Unsloth kernels....

### Efficient Architectures
Optimizing non-dense models (Mixture-of-Experts) and modern encoders (ModernBERT) for high throughput and classification.

* **[TinyQwen3 MoE](TinyQwen3_MoE/README.md)**: To demonstrate unsloth's MoE optimisations on T4 for `imdatta0/tiny_qwen3_moe_2.8B_0.7B` by finetuni...
* **[ModernBert](ModernBert/README.md)**: High-performance LLM optimization implemented with Unsloth kernels....
* **[Qwen3 MoE](Qwen3_MoE/README.md)**: To convert `unsloth/Qwen3-30B-A3B-Instruct-2507` into a reasoning model via GRPO by using OpenR1's M...
* **[bert classification](bert_classification/README.md)**: High-performance LLM optimization implemented with Unsloth kernels....

### Edge & Quantization
Shrinking models to run on phones and low-power devices using Quantization Aware Training (QAT) and sub-1B parameter scaling.

* **[Qwen3 (0 6B)-Phone Deployment](Qwen3_0_6B_Phone_Deployment/README.md)**: High-performance LLM optimization implemented with Unsloth kernels....
* **[Qwen3 (4B) Instruct-QAT](Qwen3_4B_Instruct_QAT/README.md)**: High-performance LLM optimization implemented with Unsloth kernels....
* **[Nemotron-3-Nano-30B-A3B A100](Nemotron_3_Nano_30B_A3B_A100/README.md)**: High-performance LLM optimization implemented with Unsloth kernels....
* **[Phi 4-Conversational](Phi_4_Conversational/README.md)**: High-performance LLM optimization implemented with Unsloth kernels....

### Multimodal & Audio
Beyond text: Fine-tuning robust speech-to-text and high-fidelity text-to-speech synthesis models.

* **[Whisper](Whisper/README.md)**: Optimized multimodal processing for low-latency audio/speech tasks....
* **[Oute TTS (1B)](Oute_TTS_1B/README.md)**: Optimized multimodal processing for low-latency audio/speech tasks....
* **[Orpheus (3B)-TTS](Orpheus_3B_TTS/README.md)**: Optimized multimodal processing for low-latency audio/speech tasks....
* **[Spark TTS (0 5B)](Spark_TTS_0_5B/README.md)**: Optimized multimodal processing for low-latency audio/speech tasks....

### Synthetic Data
Data curation and distillation. Using large models to generate high-quality instruction sets to improve smaller specialized models.

* **[Synthetic Data Hackathon](Synthetic_Data_Hackathon/README.md)**: High-performance LLM optimization implemented with Unsloth kernels....
* **[Meta Synthetic Data Llama3 2 (3B)](Meta_Synthetic_Data_Llama3_2_3B/README.md)**: High-performance LLM optimization implemented with Unsloth kernels....

## üõ§Ô∏è Moving to Production
These implementations are designed for 2026-scale workloads. To deploy:
1. **Distillation**: Use the Synthetic Data pipelines to transfer logic from Llama 3.2 to smaller models.
2. **Quantization**: Apply QAT or FP8 post-training quantization for edge suitability.
3. **Deployment**: Export to GGUF or vLLM for high-throughput serving.
